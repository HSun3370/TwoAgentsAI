{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model \n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import sys \n",
    "import pathlib\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Load parameters\n",
    "export_folder                    = sys.argv[1] \n",
    "batch_size                       = int(sys.argv[2])\n",
    "num_iterations                   = int(sys.argv[3])\n",
    "pretrained_path                  = sys.argv[4]\n",
    "logging_frequency                = int(sys.argv[5])\n",
    "learning_rates                   = [float(x) for x in sys.argv[6].split(\",\")]\n",
    "hidden_layer_activations         = sys.argv[7].split(\",\")\n",
    "output_layer_activations         = sys.argv[8].split(\",\")\n",
    "num_hidden_layers                = int(sys.argv[9])\n",
    "num_neurons                      = int(sys.argv[10])\n",
    "learning_rate_schedule_type      = sys.argv[11]\n",
    "export_folder_output             = sys.argv[12]\n",
    " \n",
    " \n",
    "tensorboard=\"True\"\n",
    "\n",
    "\n",
    "\n",
    "## Take care of pretrained path\n",
    "if pretrained_path == \"None\":\n",
    "    pretrained_path = None\n",
    "else:\n",
    "    pretrained_path = pretrained_path \n",
    "\n",
    "## Take care of activation functions \n",
    "hidden_layer_activations   = [None if x == \"None\" else x for x in hidden_layer_activations]\n",
    "output_layer_activations   = [None if x == \"None\" else x for x in output_layer_activations]\n",
    "\n",
    "#############################################\n",
    "## Part 1\n",
    "## Solve post tech post damage model\n",
    "#############################################\n",
    "\n",
    "## This model has three state variables\n",
    "\n",
    "v_nn_config   = {\"num_hiddens\" : [num_neurons for _ in range(num_hidden_layers)], \"use_bias\" : True, \"activation\" : hidden_layer_activations[0], \"dim\" : 1, \"nn_name\" : \"v_nn\"}\n",
    "v_nn_config[\"final_activation\"] = output_layer_activations[0]\n",
    "\n",
    "i_g_nn_config = {\"num_hiddens\" : [num_neurons for _ in range(num_hidden_layers)], \"use_bias\" : True, \"activation\" : hidden_layer_activations[1], \"dim\" : 1, \"nn_name\" : \"i_g_nn\"}\n",
    "i_g_nn_config[\"final_activation\"] = output_layer_activations[1]\n",
    "\n",
    "i_a_nn_config = {\"num_hiddens\" : [num_neurons for _ in range(num_hidden_layers)], \"use_bias\" : True, \"activation\" : hidden_layer_activations[2], \"dim\" : 1, \"nn_name\" : \"i_a_nn\"}\n",
    "i_a_nn_config[\"final_activation\"] = output_layer_activations[2]\n",
    "\n",
    "i_d_nn_config = {\"num_hiddens\" : [num_neurons for _ in range(num_hidden_layers)], \"use_bias\" : True, \"activation\" : hidden_layer_activations[3], \"dim\" : 1, \"nn_name\" : \"i_d_nn\"}\n",
    "i_d_nn_config[\"final_activation\"] = output_layer_activations[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "v_g_nn_config   = {\"num_hiddens\" : [num_neurons for _ in range(num_hidden_layers)], \"use_bias\" : True, \"activation\" : hidden_layer_activations[0], \"dim\" : 1, \"nn_name\" : \"v_g_nn\"}\n",
    "v_g_nn_config[\"final_activation\"] = output_layer_activations[0]\n",
    "\n",
    "\n",
    "v_a_nn_config   = {\"num_hiddens\" : [num_neurons for _ in range(num_hidden_layers)], \"use_bias\" : True, \"activation\" : hidden_layer_activations[0], \"dim\" : 1, \"nn_name\" : \"v_a_nn\"}\n",
    "v_a_nn_config[\"final_activation\"] = output_layer_activations[0]\n",
    "\n",
    "\n",
    "\n",
    "## Create params struct \n",
    "params = {\"batch_size\" : batch_size,  \n",
    "\"v_nn_config\" : v_nn_config, \"v_g_nn_config\" : v_g_nn_config, \"v_a_nn_config\" : v_a_nn_config, \"i_g_nn_config\" : i_g_nn_config,\"i_a_nn_config\" : i_a_nn_config,  \"i_d_nn_config\" : i_d_nn_config, \\\n",
    "\"num_iterations\" : num_iterations, \"logging_frequency\": logging_frequency, \"verbose\": True, \"load_parameters\" : None, \"norm_weight\" : 0.9,\n",
    "\"pretrained_path\" : pretrained_path, 'tensorboard' : tensorboard, \"learning_rate_schedule_type\" : learning_rate_schedule_type }\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "if params[\"learning_rate_schedule_type\"] == \"None\":\n",
    "    lr_schedulers = learning_rates\n",
    "    params[\"optimizers\"] = [tf.keras.optimizers.Adam( learning_rate = lr_scheduler) for lr_scheduler in lr_schedulers]\n",
    "elif params[\"learning_rate_schedule_type\"] == \"piecewiseconstant\":\n",
    "    boundaries            = [int(round(x)) for x in np.linspace(0,num_iterations,5)][1:-1]\n",
    "    values_list           = [[learning_rate / np.power(2,x) for x in range(len(boundaries)+1)] for learning_rate in learning_rates]\n",
    "    lr_schedulers         = [ tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values) for values in values_list]\n",
    "    params[\"optimizers\"] = [tf.keras.optimizers.Adam( learning_rate = lr_scheduler) for lr_scheduler in lr_schedulers]\n",
    "elif params[\"learning_rate_schedule_type\"] == \"sgd+piecewiseconstant\":\n",
    "    boundaries            = [int(round(x)) for x in np.linspace(0,num_iterations,5)][1:-1]\n",
    "    values_list           = [[learning_rate / np.power(2,x) for x in range(len(boundaries)+1)] for learning_rate in learning_rates]\n",
    "    lr_schedulers         = [ tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values) for values in values_list]\n",
    "    params[\"optimizers\"] = [tf.keras.optimizers.legacy.SGD( learning_rate = lr_scheduler) for lr_scheduler in lr_schedulers]\n",
    "elif params[\"learning_rate_schedule_type\"] == \"sgd\":\n",
    "    lr_schedulers = learning_rates\n",
    "    params[\"optimizers\"] = [tf.keras.optimizers.legacy.SGD( learning_rate = lr_scheduler) for lr_scheduler in lr_schedulers]\n",
    "\n",
    " \n",
    "params[\"export_folder\"]  = export_folder +  \"/TrainingResults\"\n",
    "\n",
    " \n",
    "  \n",
    "test_model = model.model(params)\n",
    "test_model.export_parameters()\n",
    "test_model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
